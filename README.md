# CodeChef 

![프로젝트 대표 이미지](./CodeChef.png)

현업 개발자가 예비 개발자의 코드를 리뷰하고 성장하는 커뮤니티 입니다.
---

## KEY Summary

### 🍁 **기술적 의사 결정: Elasticsearch를 사용해 랭킹 시스템을 구현한 이유 **

1. **배경**
   - 코드 리뷰 커뮤니티에선 코드에 대한 문제를 해결하거나, 정보를 찾기 위해 키워드로 검색을 많이 시도합니다.
     그러므로 사용자들이 자주 검색하는 키워드를 랭킹으로 보여주면 비슷한 문제를 가진 사용자들이 관련 질문과 답변을 쉽게 찾을 수 있습니다.
     또 주요 주제가 실시간으로 반영되면서, 커뮤니티의 흐름을 파악하는것이 중요했습니다.

2. **선택지**
   1. MySQL을 사용하여 검색어와 검색 횟수를 DB에 저장하고, SQL 쿼리를 사용해 랭킹 계산하는 방법
   2. Redis의 ZSet을 사용하여 실시간 검색어 랭킹 계산하는 방법
   3. Elasticsearch의 Terms Aggregation을 사용하여 랭킹 계산하는 방법


3. **요구사항**
   1. 특정 기간 동안 검색된 검색어 중 **가장 많이 검색된 10개 키워드**와 해당 **검색 횟수**를 집계하여 반환해야 한다.
   2. 검색어는 로그로 저장되며, 대규모 데이터에도 처리가 적합하여야 한다.
   3. 새로운 검색 요청이 들어올 경우, 해당 데이터는 실시간으로 저장되고 다음 랭킹 결과에 반영되어야 한다.

4. **도입 이유 및 해결 방안**
   - MySQL은 데이터의 일관성 유지와 데이터 저장에 강점이 있고 복잡한 쿼리의 처리가 가능하지만, 실시간 업데이트에 취약하고 대규모 데이터 처리에서 비효율적입니다.
      
     Redis의 ZSet은 실시간 업데이트 측면에서는 적합하지만, 메모리 기반으로 동작하므로 저장 가능한 데이터의 크기가 서버 메모리 용량에 의존합니다.
     즉, 검색 로그가 점점 증가하면, 메모리 한계로 인해 데이터 손실이나 성능 저하가 발생할 수 있습니다. 또한 별도의 시각화가 어렵다는 단점이 있습니다.
   
     Elasticsearch는 Redis에 비해 대규모 데이터 처리에 적합할 뿐만 아니라, Terms Aggregation 기능으로 다양한 필터링 기능을 쉽게 추가할 수 있습니다. 또한, Kibana를 통해 손쉽게 데이터 시각화도 가능합니다.
     그러므로 우리 프로젝트에선 Elasticsearch를 사용하여 실시간 인기 검색어 랭킹을 구현하기로 결정하였습니다.
---

### 🍁 **트러블 슈팅: **

1. **문제**  
   - 실시간 게시물 랭킹 이나 유저 랭킹을 조회시에 어떠한 자료구조를 선택하는 것이 적합할까에 대해서 고민이 발생하였습니다.

   **해결 방안**  
   - 레디스의 Sorted Set 자료 구조를 사용하게 되었습니다.
     여러가지 자료구조 중(List,String,Set … 등등 ) Sorted Set을 사용하게 된 이유는, 
     점수나 조회수 기준으로 3등까지 랭킹을 조회해야하는 기능을 구현해야 했어야 했습니다.
     이러한 요구사항을 바탕으로 Sorted Set의 특징으로는 각 요소는 고유한 값(value)과 점수(score)를 가집니다 이러한 형태로 데이터를 삽입 하고, 
     데이터 삽입 시점에 점수를 기준으로 **자동으로 오름차순 정렬**이 되고, 정렬 연산 없이 정렬된 데이터를 효율적으로 조회 가능하고, 
     일반적인 시간 복잡도로는 **O(log(N))** 이므로 프로젝트에 랭킹 구현에 적합하다고 판단 했습니다.

2. **문제**  
   - 실시간 게시물 조회나 랭킹 조회시에 캐싱을 사용하는데 어떤식으로 레디스에 테이터를 관리하는것이 적합할까에 대해서 고민이 발생했습니다.

   **해결 방안**  
   - **Write-Through 및 Read-Through 전략 을 사용하게 되었습니다.**
     **쓰기전략에는 Write-Through 전략을 선택한 이유는 다음과 같습니다. 저희 프로젝트에는 캐싱과 db에 일관성 있는 데이터, 
     레디스의 최신 상태를 유지를 하는게 가장 중요하다고 판단 했습니다. 그래서 데이터 쓰기 시점에 DB와 레디스에 동시에 기록되고, 
     쓰**기 시점에 즉시 업데이트 되므로 캐시 데이터가 최신 데이터로 유지가 가능한**Write-Through 전략을 선택하게 되었습니다.**

     읽기전략에는 **Read-Through 전략**을 선택한 이유는 다음과 같습니다. 당시 프로젝트에 **조회 요청이 빈번하게 발생하며,
     빠른 응답 속도가 사용자 경험에 매우 중요**하다고 판단했기 때문입니다. Read-Through 전략은 데이터 조회시 **캐시에서 데이터를 우선적으로 조회**하고, 
     만약 캐시에 데이터가 없는 경우에만 **DB에서 데이터를 가져와 캐시에 저장**합니다. 이를 통해, **대부분의 읽기 요청을 캐시에서 처리**함으로써 DB 부하를 줄이고,
     **빠른 응답 속도**를 제공할 수 있습니다. 또한, 캐시 미스(Cache Miss) 발생 시 데이터를 자동으로 갱신하는 장점이 있어서 선택하게 되었습니다.

---

## 인프라 아키텍처 & 적용 기술

### 아키텍처 다이어그램
![Infra Architecture](./service_architecture.png)

위 아키텍처는 **** 구조를 나타냅니다.  


<details>
<summary><b>📦 적용 기술 상세보기</b></summary>

### 💾 ****
- **Redis**  
  - 

### 📬 **메시징 시스템**
- **Kafka**  
  - 

### 🌐 **인프라 및 배포**
- **Docker**  
  - 
- **Prometheus & Grafana**  
  - 

</details>



## 주요 기능

### 🍁 **검색 : Elasticsearch를 사용한 검색 기능 구현**
- Elasticsearch를 사용하여 게시글 검색 기능 구현

### 🍁 ****
- 

### 🍁 ****
- 

---

## 기술적 고도화
<details>
<summary><b>🍁 인덱스 도입으로 검색 성능 30% 개선</b></summary>
[문제 인식]

게시글 검색을 위해 풀 테이블 스캔을 하는건 너무 비효율적이고 성능 소비가 심하다.

대량의 데이터가 생길수록 응답 속도는 더 큰 차이를 보인다. 그래서 풀 테이블 스캔이 아니라, 인덱스를 생성하여 데이터 조회 속도를 높이고, 리소스 사용을 최적화 한다.

인덱스

책의 색인처럼 특정 데이터를 빠르게 찾을 수 있도록 하는 특별한 데이터 구조이다.

- **B-Tree 인덱스**: 범위 검색, 정렬된 데이터 조회에 적합하여 대부분의 데이터베이스에서 기본적으로 사용된다.
- **Hash 인덱스**: 특정 값과 일치하는 데이터를 찾는 데 빠르며, 범위 검색에는 적합하지 않다.

[선택 이유]

- **검색 속도를 높인다**: 인덱스가 있으면 특정 데이터 위치를 바로 찾아가니까 전체 테이블을 검색할 필요 없이 빠르게 결과를 얻는다.
- **응답 시간을 줄인다**: 쿼리 실행 시 필요한 데이터만 추려내기 때문에, 응답 시간이 짧아져 사용자에게 빠르게 결과를 보여준다.
- **데이터베이스 성능을 개선한다**: 인덱스를 사용하면 데이터베이스가 더 적은 자원으로 원하는 데이터를 찾아내 성능이 전반적으로 향상된다.
- **처리 부담을 낮춘다**: 전체 테이블 스캔을 하면 데이터가 많아질수록 부담이 커지지만, 인덱스는 필요한 데이터만 조회하기 때문에 부담이 훨씬 덜하다.
- **쿼리 최적화를 돕는다**: 인덱스가 적절하게 설정되어 있으면 복잡한 쿼리에서도 최적의 검색 경로를 찾을 수 있어 쿼리가 효율적으로 실행된다

[해결 방안]	

Board 엔티티에 @Index 어노테이션을 설정하여, 기본 인덱스를 설정하였다.

하지만 애플리케이션 실행 중, 오류가 발생하였는데, MYSQL의 InnoDB는 인덱스의 최대 크기를 3072byte로 제한을 한다.

![](assets/images/index/entity.png)

Board 엔티티의 title과 contents를 중심으로 검색하려고 하면, 4 * 2200 즉 8800바이트가 발생한다.

그래서 우리는 기본 인덱스를 사용하지 않고, 이를 해결해줄 수 있는 부분 인덱스를 사용하기로 한다.

![](assets/images/index/createPartialIndex.png)

애플리케이션을 실행할 때 Local에서 CREATE INDEX boards_title_contents_partial_index ON boards (title(50), contents(200))”; 쿼리를 실행한다.

이는 title의 길이 50, contents의 길이 200까지만 인덱스를 설정한다는 뜻이다.

그래서 인덱스를 부분으로 걸어 인덱스의 크기를 줄이고 저장 공간을 절약한다.

![](assets/images/index/checkIndex.png)

인덱싱이 정상적으로 등록됐다.

![](assets/images/index/jmeter_index_output.png)

10만개의 더미 데이터를 넣고 조회를 100번 하여 성능 비교를 했는데 놀랍게도 차이가 없다.

![](assets/images/index/old_query.png)

확인 해보니 LIKE문에서 인덱스을 걸려면 CONCAT문과 함께 사용해야 한다.

![](assets/images/index/new_query.png)

코드를 이렇게 수정하면 인덱스가 적용 된다.

![](assets/images/index/range.png)

type = range로 boardSearch 쿼리 인덱싱 적용 완료 확인

[해결 완료]
- 결과

| 처리 방식 | 평균 응답시간 | 처리량 | 표준 편차 | 최소 응답시간 | 최대 응답시간 |
| --- | --- | --- | --- | --- | --- |
| 인덱스 | 38 | 25.9/sec | 2.83 | 37 | 65 |
| DB | 54 | 18.4/sec | 1.17 | 53 | 62 |

인덱싱을 적용한 쿼리가 이전 쿼리에 비해 약 30%의 빠른 평균 응답 속도와 처리량을 보인다.
</details>

<details>
<summary><b>🍁 배포 ci/cd</b></summary>
   
### [내가 구현한 기능]

### CICD

---

### [주요 로직]

**GitHub Actions 시나리오**

개발자가 `main` 브랜치에 푸시하면, GitHub Actions 워크플로우가 자동 실행된다. 해당 워크플로우는 다음 단계를 포함한다.

1. **리포지토리 체크아웃**
    - `actions/checkout@v4`를 통해 애플리케이션 코드 리포지토리를 체크아웃한다.
2. **EC2 SSH 설정**
    - EC2 연결에 필요한 `EC2_HOST`, `EC2_USER`, `SSH_PRIVATE_KEY` 환경 변수를 사용해 SSH 설정을 구성한다.
    - `SSH_PRIVATE_KEY`를 파일로 저장해 SSH 접근 권한을 설정한다.
3. **자바 환경 구성**
    - `actions/setup-java@v4`를 사용해 자바 17 환경을 설치하고, Gradle 빌드를 위한 설정을 마친다.
4. **Gradle 빌드**
    - `gradlew` 파일에 실행 권한을 부여하고, `./gradlew build` 명령어로 프로젝트를 Gradle 빌드해 애플리케이션 JAR 파일을 생성한다.
5. **Docker 이미지 빌드 및 DockerHub 푸시**
    - `docker/login-action@v1`를 통해 DockerHub에 로그인한 후, Docker 이미지를 `DOCKER_USERNAME`/`my-app:latest` 이름으로 빌드하여 DockerHub에 푸시한다.
6. **EC2 서버에 SSH 접속 후 배포**
    - `appleboy/ssh-action@v1.1.0`을 사용해 EC2 서버에 SSH 접속한 후, 다음과 같은 배포 과정을 진행한다:
        - DockerHub에 로그인 후, 기존 애플리케이션 컨테이너를 중지하고, 사용하지 않는 컨테이너 및 이미지를 정리해 공간을 확보한다.
        - DockerHub에서 최신 애플리케이션 이미지를 `pull`한 후, 환경 변수 설정 파일 `.env`를 적용해 포트 8080에서 애플리케이션 컨테이너를 실행한다.

---

이를 통해 EC2 서버에서 최신 애플리케이션 상태가 유지될 수 있도록 하며, 자동화된 배포 과정을 완성한다.

---

### [배경]

기존 수동 배포 과정은 속도 저하와 반복 작업으로 인한 비효율성을 초래했다. 자동화된 CI/CD 프로세스를 도입해 배포를 최적화할 필요가 있었다.

---

### [요구사항]

1. CI/CD 파이프라인 자동화
2. EC2 서버와의 안전한 통신 및 배포 설정
3. Docker Hub와의 간편한 연계 및 이미지 관리

---

### [선택지]

1. Jenkins
2. GitHub Actions

---

### [의사결정/사유]

**배경**

당시 EC2 프리 티어 인스턴스를 사용 중이며, 메모리는 1GB이다. Docker와 Jenkins를 동시에 구동하려 했으나 성능이 크게 저하되는 문제가 발생했다. Jenkins는 일반적으로 2GB 이상의 메모리를 요구하고 Docker로 구동할 때에도 메모리 여유가 필요해, 현재 인스턴스로는 Docker와 Jenkins를 함께 운영하기 어려웠다. 결과적으로 최소 4GB 이상의 메모리가 필요할 것으로 보였다.

**문제 해결**

EC2 인스턴스를 업그레이드하거나, Jenkins를 로컬에서 구동하는 방안을 검토했으나 Jenkins 대신 **GitHub Actions**를 사용하기로 결정했다. 이는 Jenkins의 설정 부담을 줄이고 EC2 환경에서 CI/CD를 효과적으로 구현할 수 있는 대안으로 판단했다.

**성과**

GitHub Actions를 통해 CI/CD 파이프라인을 자동화하며 수동 배포 과정을 효율적으로 개선했다. 배포 속도가 크게 단축되었고 인적 오류가 줄어들어 전체적인 개발 생산성이 높아졌다.

---

### [회고]

### 1. **Jenkins 대신 GitHub Actions 사용의 이점**

GitHub Actions는 Jenkins와 비교해 다음과 같은 장점을 지닌다:

- **간편한 통합**: GitHub Actions는 GitHub 리포지토리와 바로 연결되어 추가 설정 없이 CI/CD 파이프라인을 쉽게 구성할 수 있다. Jenkins는 GitHub 통합을 위해 웹훅이나 플러그인 설정이 필요하다.
- **비용 절감**: GitHub Actions는 퍼블릭 리포지토리에서 무료로 제공되며, 기본 요금제에도 일정량의 워크플로우 사용이 포함되어 비용 절감에 효과적이다. Jenkins는 서버 운영과 클라우드 사용에 따른 추가 비용이 발생할 수 있다.
- **관리 편의성과 유연한 스케일링**: GitHub Actions는 서버리스로 제공되며 추가 서버 관리가 필요 없고, Jenkins와 달리 확장 시 별도 서버 관리가 필요 없다.
- **YAML 기반 구성**: 설정 파일이 `.yml` 형식으로 기록되어 버전 관리와 코드 리뷰가 용이해 협업에 유리하다.
- **병렬 실행 지원**: GitHub Actions는 다양한 작업을 병렬로 쉽게 실행할 수 있으며, 자체 호스팅 러너로 특정 작업을 분산 처리할 수 있다. Jenkins도 병렬 빌드를 지원하지만, 설정이 더 복잡하다.

### 2. **GitHub Actions 사용 시 Docker Hub의 장점**

Docker 이미지를 저장할 레지스트리로 Docker Hub를 선택하는 경우, AWS ECR과 비교해 다음과 같은 장점이 있다:

- **사용성과 접근성**: Docker Hub는 Docker 커뮤니티의 기본 레지스트리로 널리 사용되며, 퍼블릭 이미지의 배포와 접근이 용이하다.
- **간편한 설정**: Docker Hub는 GitHub Actions와 쉽게 연동되며 간단한 인증으로 설정할 수 있다. AWS ECR을 사용하려면 IAM 역할 및 정책 설정 같은 추가 작업이 필요하다.
- **공개 이미지 관리 편리성**: 오픈 소스 프로젝트나 외부에 Docker 이미지를 배포할 경우 Docker Hub가 더 유리하다.
- **환경 독립성**: Docker Hub는 다양한 클라우드 환경과 온프레미스에서도 쉽게 사용할 수 있어, ECR보다 환경 독립성이 높다.

---

위와 같은 이유로 EC2 프리 티어 환경에서는 Jenkins 대신 GitHub Actions와 Docker Hub를 사용해 CI/CD 파이프라인을 구성하는 것이 효율적인 대안이라 판단했다.
<img width="817" alt="스크린샷 2024-11-14 오전 10 13 52" src="https://github.com/user-attachments/assets/8d51c968-96ed-44b5-9487-f4b43b992070">
</details>

<details>
<summary><b>🍁 실시간 게시물 랭킹 조회 (캐싱)</b></summary>
실시간 게시물 랭킹 조회 DB에서의 조회와 Redis를 캐싱(Cacheable 사용)한 것에서의 조회
   
![image (1)](https://github.com/user-attachments/assets/bdc65203-a763-4e83-a861-7410714e6985)


막대 그래프

![output (2)](https://github.com/user-attachments/assets/8e91a780-cd4c-4184-880f-e4135ee30560)

위 그래프는 `DB 랭킹 조회`와 `redis 랭킹 조회`의 성능을 비교한 것이다. 각 지표에 대한 설명은 다음과 같다:

1. **Average Response Time**: 평균 응답 시간에서 Redis가 DB보다 훨씬 빠르다 (DB: 26ms, Redis: 13ms). Redis가 캐싱을 통해 더 빠른 응답을 제공하고 있음을 나타낸다.
2. **Throughput**: 처리량(초당 요청 수) 역시 Redis가 DB보다 높아 초당 더 많은 요청을 처리할 수 있다.
3. **Min and Max Response Time**: 최소 및 최대 응답 시간에서 DB의 변동 폭이 더 크다. Redis는 비교적 일관된 응답 시간을 제공하지만 DB는 요청의 최대 응답 시간이 높아질 수 있다.
4. **Standard Deviation of Response Time**: 응답 시간의 표준 편차 역시 DB가 높아 응답 시간의 일관성이 낮다.
5. **Received KB/sec and Sent KB/sec**: 초당 송수신된 데이터 양에서 Redis가 더 높은 값을 보이지만, 큰 차이는 없다.

전체적으로 Redis가 DB보다 더 빠르고 안정적인 성능을 보이며, 캐시를 사용하는 것이 성능 향상에 도움이 됨을 확인할 수 있다.

---

## 인기 게시물 실시간 랭킹 조회 기능

### 1. 구현 기능

사용자들이 조회수 기준으로 인기 게시물을 실시간으로 확인할 수 있도록 **인기 게시물 랭킹 조회 기능**을 구현했습니다. 주요 목표는 빠른 응답 속도와 높은 조회 성능을 통해 사용자 경험을 개선하고, 시스템 부하를 줄이는 것이었습니다.

### 2. 주요 로직

이 기능은 Redis 캐싱을 활용해 사용자에게 실시간 인기 게시물을 제공합니다. 구체적인 로직은 다음과 같습니다:

- **Redis 캐시와 @Cacheable 어노테이션**을 사용하여 인기 게시물 데이터를 캐시에 저장하고, 조회 요청이 발생할 때마다 캐시에서 데이터를 불러오도록 했습니다. 이를 통해 DB 접근 없이도 신속한 응답이 가능합니다.
- **인기 게시물 데이터 및 상세 정보는 Redis 캐시에 저장**되어 있어, 조회 요청이 있을 때 캐시에서 즉시 반환됩니다.

### 3. 구현 배경 및 요구사항

이 기능은 다음과 같은 문제 해결 요구사항을 기반으로 설계되었습니다.

- **기존 문제점**: 초기에 DB에서 직접 인기 게시물을 조회하는 방식이었으나, 다수의 요청이 들어올 경우 DB 부하가 가중되어 응답 속도가 느려지는 문제가 있었습니다.
- **해결 필요성**: 실시간으로 사용자에게 인기 게시물 정보를 빠르게 제공해야 했기에, **DB 조회를 최소화하면서 신속하게 데이터 접근이 가능한 Redis 캐싱**이 필요하다고 판단했습니다.

### 4. 의사 결정 과정

기술 선택 과정에서 고려한 두 가지 방안을 비교하였습니다:

- **DB에서 직접 조회**: DB에 있는 데이터를 그대로 조회하는 방법은 구현이 간단하지만, 속도가 느리고 요청이 많아질 경우 DB에 과부하가 걸립니다.
- **Redis 캐싱 사용**: Redis는 메모리 기반의 캐시로, 빠른 응답을 제공하고 DB 접근을 줄여 부하를 낮출 수 있습니다. 하지만 캐시 설정을 위한 추가 개발이 필요합니다.

이를 바탕으로, **신속한 응답과 안정성을 고려해 Redis 캐시**를 사용하여 사용자에게 인기 게시물 정보를 제공하는 것이 가장 효율적이라고 판단했습니다.

### 5. 문제 해결 과정

**문제 정의**: Redis 캐싱을 설정했음에도 성능 개선이 이루어지지 않는 현상이 있었습니다. 캐시어블(@Cacheable) 어노테이션을 사용했지만, 여전히 레포지토리에서 데이터를 조회하고 있었기 때문에 캐시의 이점이 줄어들었습니다.

**해결 방안**:

- 캐시가 없는 경우에만 DB를 조회하고, 조회한 데이터를 Redis에 저장하는 방식으로 코드 로직을 수정했습니다. 이를 통해 불필요한 DB 접근을 방지하고 캐싱 효과를 극대화했습니다.

**결과**: 문제 해결 후, 응답 속도가 DB만 사용할 때보다 26ms에서 13ms로 단축되었고, 초당 처리 가능한 요청 수도 증가했습니다. 응답 시간의 변동폭도 줄어들어, 안정적인 성능을 확보할 수 있었습니다.

### 6. 성과 및 회고

- **응답 속도 개선**: Redis 캐시 도입으로 실시간 인기 게시물 랭킹을 빠르게 조회할 수 있게 되어, 사용자 응답 시간이 크게 향상되었습니다.
- **안정적인 성능**: Redis 캐시는 DB에 비해 일관된 성능을 유지하며, 변동폭이 적어 사용자에게 더 안정적인 경험을 제공했습니다.
- **DB 부하 감소**: DB 접근 횟수를 줄임으로써 전체 시스템 부하가 감소하였고, 더 많은 요청을 안정적으로 처리할 수 있게 되었습니다.

**기술 선택 회고**: 

- Redis Sentinel을 선택한 이유
    - 빠른 조회 성능뿐만 아니라 **서비스의 고가용성과 장애 대응 능력**을 확보하기 위함이었습니다. Redis Sentinel을 통해 **장애 발생 시 자동으로 캐시 서버를 감지하고 복구**하여, 캐시 시스템이 다운되더라도 즉각적인 복구가 가능하도록 설정했습니다. 덕분에 사용자들은 실시간으로 인기 게시물 데이터를 안정적으로 조회할 수 있었습니다.
</details>

<details>
<summary><b>🍁 게시글 조회 동시성 1 (비관적 락)</b></summary>
   
### 내가 구현한 기능

**동시성 문제 해결을 위한 조회수 업데이트 최적화**

### 주요 로직

게시물 조회 시, 조회수 업데이트로 인해 발생하는 동시성 문제를 해결하는 로직을 구현하였습니다. 캐싱을 위해 Redis를 사용하지만, DB에 조회수를 직접 업데이트하는 코드가 동시성 문제를 유발하고 있어, 이 문제를 해결하기 위해 **비관적 락(Pessimistic Lock)** 전략을 도입하였습니다.

### 배경

많은 양의 요청이 올 때 게시물 조회수 업데이트 로직에서 조회수 업데이트가 제대로 반영되지 않는 문제를 확인하였습니다.

### 요구사항

1. 조회수 업데이트 시 DB 성능 저하를 최소화한다.
2. 게시물 조회수는 정확하게 반영되도록 한다.
3. 대량의 동시 요청 시에도 안정성을 유지한다.

### 선택지

1. **비관적 락(Pessimistic Lock)**: 레포지토리 계층에서 데이터를 읽고 쓸 때마다 락을 걸어 동시 접근을 방지한다.
2. **낙관적 락(Optimistic Lock)**: 트랜잭션 종료 시점에서만 충돌 검사를 하고, 충돌 발생 시 재시도로 문제를 해결한다.

### 의사결정/사유

**비관적 락**을 선택한 이유는 다음과 같습니다:

1. **동시성 문제 해결**: Redis에 실시간 조회수를 저장하고, DB에 전체 조회수를 기록하는 구조에서, 조회수 증가가 실패 없이 일관되게 반영되어야 했습니다. Redis를 먼저 업데이트하고 DB에 저장하는 방식이기 때문에, 조회수가 부정확하게 증가할 위험을 최소화해야 했습니다. 비관적 락은 데이터를 수정하는 동안 다른 트랜잭션의 접근을 막아주므로 이러한 문제를 해결할 수 있었습니다.
2. **안정성 향상**: 비관적 락은 트랜잭션이 실행되는 동안 다른 트랜잭션의 접근을 차단하여 중복 증가를 방지합니다. 따라서, 낙관적 락이 제공할 수 없는 재시도 없이도 정확한 조회수를 유지할 수 있었습니다.
3. **정확성 보장**: 비관적 락을 적용하면 Redis와 DB 간의 조회수 불일치를 방지할 수 있습니다. Redis는 실시간 조회수 캐싱에 이용하며 한 시간 간격으로 캐시를 삭제하여 최신 정보를 유지하지만, DB에는 전체 조회수를 지속적으로 기록하도록 하였습니다. 이 접근 방식은 대량의 요청이 들어와도 정확한 조회수 관리가 가능하게 합니다.

### 성과

비관적 락을 도입한 결과, 실시간 인기 게시물 조회수 업데이트 성능이 개선되었고, 동시 요청이 많은 상황에서도 조회수가 일관되게 반영되는 성과를 거두었습니다. 이로써 사용자가 실시간으로 조회수를 정확하게 확인할 수 있게 되었습니다.

### 회고

조회수 업데이트 로직에 비관적 락을 적용함으로써, Redis와 DB 간의 조회수 불일치를 방지하며 성능과 정확성을 모두 개선할 수 있었습니다. 낙관적 락도 검토했으나, 동시성 환경에서 재시도와 캐시 불일치 문제가 발생할 수 있어 비관적 락을 선택한 것이 올바른 결정이었다고 판단합니다. 낙관적 락을 사용하게 되면 재시도를 하게 되어 Redis의 값의 정확성을 보장할 수 없었기에 비관적 락을 선택한 것이 좋은 방법이었다고 생각합니다.

### 피드백 및 문제 정의

- 트랜잭션 내에서 롤백이 발생하면 DB만 롤백되고 Redis의 상태는 유지되는 문제가 발견되었습니다. 이는 데이터 일관성 측면에서 큰 문제로, 향후 해결 방안을 모색해야 할 부분입니다.
- AOP를 활용하여 트랜잭션 이벤트 리스너를 사용하고, 커밋되는 시점에만 Redis를 업데이트하는 방안을 고려할 수 있습니다.
- 또한, DB 업데이트를 먼저 진행하고 Redis를 업데이트하는 순서로 코드를 변경할 경우, DB에서 문제가 발생하면 Redis는 업데이트되지 않으므로 안정성을 높일 수 있을지도 모릅니다.
- 이러한 접근이 실질적으로 효과적인지를 확인하기 위해 테스트가 필요합니다.
- **코드 변경 전**:
    
    ```java
    java
    코드 복사
    @Transactional
    public void 게시글조회() {
        // 1. Redis 조회수 증가
        board.view++;
    
        if (true) {
            throw new RuntimeException(); // 예외 발생 시 Redis 조회수 반영됨
        }
    
        // 2. DB 조회 및 조회수 증가
    }
    
    ```
    
- **코드 변경 후**:
    
    ```java
    
    @Transactional
    public void 게시글조회() {
        // 1. DB 조회 및 조회수 증가
        // 2. Redis 조회수 증가 (트랜잭션 성공 시에만 반영)
    
        if (true) {
            throw new RuntimeException(); // 예외 발생 시 Redis 조회수 미반영
        }
    }
    
    ```
    

> 트랜잭션 내에서 예외가 발생하면 Redis 조회수는 반영되지 않고, DB 롤백 시 데이터 일관성이 유지됩니다. 이를 위해 추후 **트랜잭션 이벤트 리스너**를 사용해 커밋 시점에 Redis에 조회수를 반영하도록 설정하는 방향으로 수정을 하여 데이터 정확성을 더욱 강화할 계획입니다.
>
</details>

<details>
<summary><b>🍁 게시글 조회 동시성 2 (낙관적 락)</b></summary>
낙관적 락 실행
<img width="836" alt="스크린샷 2024-11-05 오후 9 14 38" src="https://github.com/user-attachments/assets/5f7a7e3d-2b8f-42ed-aa7c-0ef5db458cd5">

비관적 락 실행
<img width="836" alt="스크린샷 2024-11-05 오후 9 17 12" src="https://github.com/user-attachments/assets/aa919d21-0f4b-4efc-9e9f-b0c7472cbec6">

first test가 비관적 락, second test가 낙관적 락

![first가 비관, second가 낙관](https://github.com/user-attachments/assets/6e9d0e5f-028f-42f4-9679-2f322368880b)


### [내가 구현한 기능]

**동시성 문제 해결을 위한 조회수 업데이트 최적화**

---

### [주요 로직]

실시간 인기 게시물 조회 시 발생하는 조회수 업데이트 동시성 문제를 해결하기 위해 **락(lock) 전략**을 도입했습니다. 초기에는 비관적 락을 사용하여 동시성 문제를 제어했으며, 이후 트랜잭션 커밋 시점에만 Redis에 조회수를 반영하는 방식으로 코드가 수정되면서 **낙관적 락**으로 전환할 수 있었습니다. Redis 캐싱을 활용해 실시간 조회수를 관리하며, 낙관적 락을 통해 성능을 최적화했습니다.

---

### [배경]

실시간 인기 게시물 기능은 높은 동시성을 요구하는 작업으로, 기존 방식에서는 동시 요청이 많을 경우 조회수가 정확하게 반영되지 않는 문제가 발생했습니다. Redis 캐시를 사용해 실시간 조회수를 반영했으나, DB와 Redis 간의 불일치로 조회수가 부정확하게 증가하거나 반영되지 않는 상황이 발생하여 문제를 해결할 필요가 있었습니다.

---

### [요구사항]

1. 실시간 조회수 업데이트 시 DB 성능을 유지하고 부하를 최소화해야 합니다.
2. 조회수 업데이트 시 인기 게시물의 조회수가 정확히 반영되어야 합니다.
3. 동시 요청이 많은 상황에서도 조회수의 일관성을 유지해야 합니다.

---

### [선택지]

1. **비관적 락(Pessimistic Lock)**: 조회수 증가 트랜잭션 동안 다른 접근을 막아 동시성 문제를 방지하는 방식입니다.
2. **낙관적 락(Optimistic Lock)**: 트랜잭션 종료 시점에서만 충돌을 검토하며, 충돌이 발생할 경우 재시도하여 문제를 해결합니다.

---

### [의사결정/사유]

- **초기 결정: 비관적 락 사용**
    - **데이터 일관성 문제 해결**: 초기에는 비관적 락을 사용했습니다. 낙관적 락을 사용하면 충돌 발생 시 재시도로 해결할 수 있지만, 재시도가 발생하는 동안 Redis에 반영된 값이 DB와 일치하지 않을 수 있었습니다. 조회수 증가가 반복되면서 Redis와 DB 간의 조회수가 일치하지 않는 상황을 방지하고자 비관적 락을 통해 데이터 접근을 제어했습니다.
    - **트랜잭션 내 롤백 문제**: 비관적 락을 통해 데이터 일관성을 개선하려 했으나, 트랜잭션 내에서 롤백이 발생하면 DB만 롤백되고 Redis는 그대로 유지되는 문제가 발생했습니다. 이는 조회수의 데이터 정확성에 영향을 미치는 큰 문제였으며, 이를 해결하기 위해 커밋된 시점에서만 Redis에 조회수를 반영하는 트랜잭션 이벤트 리스너를 도입했습니다.
- **낙관적 락으로 전환**
    - **트랜잭션 이벤트 리스너 도입 효과**: 트랜잭션 이벤트 리스너를 사용해 트랜잭션이 커밋된 이후에만 Redis에 조회수를 반영하도록 설정하면서, 이제는 낙관적 락을 사용할 수 있는 환경이 마련되었습니다.
    - **조회수 업데이트의 특성**: 조회수 증가는 단순히 숫자를 증가시키는 작업이므로 데이터 간 의존성이 낮습니다. 낙관적 락으로 전환한 후에도 충돌 발생 시 재시도로 간단히 복구할 수 있어 성능 저하가 적고 효율적입니다.
    - **낙관적 락의 성능 이점**: 비관적 락은 트랜잭션 수행 동안 락을 유지하므로 성능에 부담이 될 수 있습니다. 반면, 낙관적 락은 트랜잭션 종료 시점에서만 충돌 검토를 하여 자원 소모가 적고, 실시간 성능을 유지할 수 있습니다.
    - **동시성 요구사항 충족**: 낙관적 락은 충돌 시 즉시 재시도로 문제를 해결할 수 있어 높은 동시 요청 상황에서도 실시간 성능을 보장할 수 있었습니다.

---

### [성과]

낙관적 락을 적용한 결과, 조회수 정확도와 일관성이 크게 향상되었습니다. 트랜잭션 이벤트 리스너로 트랜잭션 커밋 후에만 Redis에 조회수를 반영하게 되어 데이터 불일치 문제가 해결되었으며, 실시간 인기 게시물의 조회수가 대량 요청 시에도 정확하게 반영되었습니다.

---

### [회고]

**기술의 장단점**: 초기에는 비관적 락을 통해 데이터 일관성을 확보하려 했으나, Redis와 DB 간 조회수 불일치 문제가 해결되지 않아 트랜잭션 이벤트 리스너를 도입했습니다. 이후 낙관적 락으로 전환하면서 성능과 일관성을 모두 확보할 수 있었습니다. 그러나 여전히 Redis 캐싱과 DB 업데이트 간의 타이밍 차이로 약간의 지연이 발생할 수 있어, 실시간 성능 모니터링이 필요합니다.

**다시 시도한다면?**: 비동기 처리를 추가하여 이벤트 리스너가 별도의 스레드에서 Redis 조회수를 업데이트하도록 개선할 수 있습니다. 이를 통해 조회수 동기화 속도를 더욱 높여 실시간 인기 게시물의 조회수 정확성과 사용자 경험을 강화할 수 있을 것입니다.

### 비동기 처리 적용 예시

```java

import org.springframework.scheduling.annotation.Async;

@Async
@TransactionalEventListener(phase = TransactionPhase.AFTER_COMMIT)
public void handleViewCountIncrement(BoardDetailEvent event) {
    String redisViewKey = "board:viewcount:" + event.getBoardId();

    Long viewCount = redisTemplate.opsForValue().get(redisViewKey) != null
            ? redisTemplate.opsForValue().increment(redisViewKey)
            : redisTemplate.opsForValue().increment(redisViewKey, 0);
    log.info("Incremented Redis view count for boardId {}: {}", event.getBoardId(), viewCount);

    // 랭킹 업데이트
    updateRanking(event.getBoardId(), viewCount);
}

```

---

### [문제 해결 과정]

### 성능 개선 요약

비관적 락에서 낙관적 락으로 전환하며 트랜잭션 커밋 후에만 Redis에 반영하는 트랜잭션 이벤트 리스너를 도입해, 동시성 문제를 해결하고 조회수 업데이트의 성능을 최적화했습니다.

---

### 문제 정의

- 실시간 인기 게시물 기능에서 동시성이 높은 상황에서 조회수가 정확하게 반영되지 않는 문제가 발생했습니다.
- Redis 캐싱만으로는 데이터 불일치 문제를 해결하기 어려웠으며, 초기의 비관적 락 방식에서도 Redis와 DB 간 일관성을 확보하기에 한계가 있었습니다.

### 가설

낙관적 락을 사용하면서 트랜잭션 커밋 후에만 Redis에 반영하도록 하면, 데이터 일관성을 유지하면서도 동시성 문제를 해결할 수 있을 것입니다.

### 해결 방안

1. **비관적 락 도입 후 낙관적 락으로 전환**: 초기에는 비관적 락으로 데이터 접근을 엄격히 제어했으나, 트랜잭션 이벤트 리스너를 통해 Redis 반영 시점을 조정하여 낙관적 락을 사용할 수 있는 구조로 전환했습니다.
2. **트랜잭션 이벤트 리스너 도입**: 트랜잭션 커밋 후에만 Redis에 조회수를 반영하게 하여 Redis와 DB 간 데이터 일관성을 유지할 수 있도록 설정했습니다.

### 해결 완료

- **결과**: 낙관적 락 적용 후 조회수 업데이트가 일관성 있게 반영되었으며, 동시성 문제로 인한 데이터 불일치도 크게 줄었습니다.
- **전후 데이터 비교**: 비관적 락 적용 시에는 조회수가 제대로 반영되지 않는 상황이 있었으나, 트랜잭션 이벤트 리스너와 낙관적 락을 조합한 이후 조회수가 정확히 반영되었으며 Redis와 DB 간 일관성도 개선되었습니다.
</details>

---

## 역할 분담 및 협업 방식

### **Detail Role**

| 이름   | 포지션   | 담당(개인별 기여점)                                                                                                            | Github 링크                       |
|--------|----------|-----------------------------------------------------------------------------------------------------------------------------|-----------------------------------|
| 송민준 | 리더     | ▶ **ELK 스택**  <br> - [Elasticsearch] 제목&내용&카테고리별 게시글 검색 <br> - [Logstash] SearchService 로그 Elasticsearch에 저장 <br> - [Kibana] Elasticsearch 시각화 & 실시간 인기 검색어 랭킹 Top10(검색 횟수 내림차순) <br> ▶ **인덱싱 (레거시)** <br> - 게시글 부분인덱싱 <br> - 인덱스 검색 성능 테스트 <br> ▶ **댓글 CRUD** <br> - 댓글 CRUD <br> - 댓글 채택 <br> ▶ **카테고리 CRUD** <br> - 게시글 [프레임워크, 언어] CUD <br> - 유저 중간테이블 [프레임워크, 언어] CRD | [🍁 깃헙링크](https://github.com/Luta13) |
| 강이원 | 부리더   | ▶ **로그인/회원가입** <br> - Auth(user)-service CRUD <br> - JWT와 Spring Security를 이용한 보안 설정 <br> - Redis를 이용한 Refresh Token 구현 <br> ▶ **user 권한, 경고 구현** <br> - 관리자: 광고성, 코드리뷰 외 잡담 글 경고 부여 <br> - 경고 횟수: 계정 BLOCK 처리 <br> ▶ **Redis Sentinel 적용** <br> - Redis 초기 설정 및 연결 테스트 <br> - Redis master-slave 구조 및 Sentinel 구축 <br> ▶ **RabbitMQ 적용** <br> - RabbitMQ 초기 설정 및 연결 테스트 <br> ▶ **배포 및 CI/CD** <br> - docker-compose 파일, dockerfile 작성 <br> - EC2를 통한 서비스 배포 <br> - Docker Hub에 도커 이미지 업로드 <br> - GitHub Actions를 통한 CI/CD 설정 <br> ▶ **실시간 게시물 랭킹 조회** <br> - Redis Sort Set을 이용해 랭킹 관리 <br> - 스케줄러 <br> - 1시간 간격으로 Redis 캐시 초기화 <br> - **캐싱** <br> - Redis 캐싱을 통한 성능 최적화 <br> - Cacheable을 이용한 캐싱 <br> ▶ **실시간 알림 기능** <br> - 알림 전송 및 읽음 처리, 알람 조회, 읽지 않은 알람만 조회 기능 구현 <br> - 댓글 작성 시 해당 게시글 작성자에게 알림 전송 <br> - 이벤트 발생 시 알림 전송 <br> - Slack (최종) <br> - RabbitMQ + Websocket (최종) | [🍁 깃헙링크](https://github.com/KangIWon) |
| 홍정기 | 팀원     | ▶ **게시물 작성 CRUD** <br> ▶ **이벤트 기능** <br> - 동시성 제어 방식의 발전 과정 및 성능 분석 <br> - 최종: 분산락 사용 <br> ▶ **인프라 CI/CD (리팩토링)** <br> - 한 서버에 통합되었던 Elasticsearch, Redis, RabbitMQ를 분산 배치 | [🍁 깃헙링크](https://github.com/jki09871) |
| 나민수 | 팀원     | ▶ **포인트** <br> - 포인트 지급, 포인트 차감, 포인트 조회 <br> ▶ **포인트 랭킹 (Redis SortedSet, 캐싱)** <br> - 실시간 유저 랭킹 (현업자, 비현업자) <br> - 지난달 유저 랭킹 (현업자, 비현업자) <br> ▶ **CloudFront** <br> - 첨부파일을 S3에 저장 후 CloudFront로 반환 <br> ▶ **결제** <br> - 구독 결제 & 환불 | [🍁 깃헙링크](https://github.com/minsoo-hub) |
| 강민주 | 팀원     | ▶ **첨부파일 CRUD** <br> - S3 Bucket <br> ▶ **실시간 채팅** <br> - 프로토콜: WebSocket, STOMP <br> - 메시지 브로커: RabbitMQ <br> - 메세징 패턴: Pub/Sub <br> - DB: Redis | [🍁 깃헙링크](https://github.com/MinjuKang727) |

---

## 성과 및 회고

### 잘된 점
- 송민준 : Elasticsearch를 사용하여 게시글 검색 부문 최적화를 하였음.
- 강이원 : 프로젝트에 필요한 여러 기술들의 초기 설정과 배포 및 CI/CD를 맡아서 프로젝트의 발판을 마련함.
- 홍정기 : 모든 서비스를 하나의 EC2에서 분리하여 각각의 EC2에 배포해 관리와 확장성을 개선함.
- 나민수 : 레디스 캐싱 전략을 찾아보고 프로젝트에 적합한 전략을 적용함.
- 강민주 : 프로토콜, 메세징 패턴, 메세지 브로커 선정의 각 과정을 심도있게 고민하고 메세지 브로커를 단계적으로 도입한 점, 그동안 튜터님께 피드백 받은 내용을 참고하여 코딩에 녹여내려 했던 부분이 좋았음. 전 과정을 꼼꼼하게 문서화, 영상화 한 점이 좋았음.

### 아쉬운 점
- 송민준 : 유사 검색을 구현하지 못해 사용자가 검색을 할 때 관련된 문제를 찾기 힘듦.
- 강이원 : Kafka를 최종 목표로 구현을 하려 했지만 구현을 하지 못했음.
- 홍정기 : ECS, 로드 밸런서, 오토스케일링을 활용한 자동화와 확장성 구현을 하지 못함.
- 나민수 : 결제 부분을 여러가지 시나리오에 대해서 자세하게 구현하지 못함.
- 강민주 : 메세지 발행 및 구독 기능만 구현하여 RabbitMQ의 외부 메세지 브로커로서의 장점(ex. 확장성, 메세지 전송 보장 등)을 잘 살리지 못하였음. 외부 메세지를 도입하였지만 실시간 채팅과 알람 기능 구현에만 사용한 것도 조금 아쉬움.

### 향후 계획
- 송민준 : 기존 검색 서비스의 로그 말고도 다양한 서비스 레이어의 로그를 수집하여 전체 시스템의 성능, 병목 현상, 에러를 파악하고
  최적화, 개선하고 싶습니다.
- 강이원 : Kafka로의 전환: 높은 트래픽 처리와 메시지 영속성을 고려하여 RabbitMQ에서 Kafka로 메시징 시스템을 전환해볼 것 같습니다. 대규모 데이터 스트리밍을 효율적으로 처리하고 다양한 분석 및 실시간 데이터 처리가 가능하게 하기 위해서 입니다.
- 홍정기 : ECS와 Fargate를 도입해 컨테이너 기반 자동 확장성을 구현하고 서비스 관리 부담을 줄이는 한편, 로드 밸런서를 활용해 트래픽을 효율적으로 분산시키고 서비스 가용성과 안정성을 더욱 강화할 계획입니다.
- 나민수 : 구독 부분에 조금더 안정적으로 구독 서비스를 사용할수 있도록  결제& 환불시 일어날수 있는 상황들을 더 생각해보고,
 추가적으로 개선해고싶습니다.
- 강민주 : RabbitMQ를 외부 메세지 브로커로 다중 서버 환경에서 메세지 동기화 구현 및 최적화,
외부 메세지 브로커를 실시간 채팅과 이벤트 알람 용으로만 사용하고 있는데 팀원의 동시성 문제에서 순서 보장 문제 해결 부분에도 작업 큐로 도입해 보면 좋을 것 같음.
